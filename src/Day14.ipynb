{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4091c0c8",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c7aa6b",
   "metadata": {},
   "source": [
    "### Load digits from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de0d4456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5615ff41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22f4080a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(digits.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5945e0",
   "metadata": {},
   "source": [
    "### Lets understand our raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fcbf6ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "        [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "        [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "        [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "        [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "        [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "        [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "        [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "        [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "        [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "        [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "        [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "        [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "        [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "        [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "        [ 0.,  1.,  8., ..., 12.,  1.,  0.]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01096aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  3., 12., 12.,  2.,  0.],\n",
       "       [ 0.,  0.,  7., 15., 16., 16.,  0.,  0.],\n",
       "       [ 0.,  4., 15.,  9., 14., 16.,  3.,  0.],\n",
       "       [ 0.,  2.,  0.,  0., 14., 16.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., 14., 16.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., 15., 13.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., 16., 14.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  3., 16., 13.,  2.,  0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images[1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "037f1874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f80102dc220>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25d198e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f00a1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3cd9bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c25d431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8a2aaf",
   "metadata": {},
   "source": [
    "### Image data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bcdc331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Data Shape (1797, 64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Image Data Shape\" , digits.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7e28d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d102fa88",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/understanding-train-test-split-scikit-learn-python-ea676d5e3d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aeb0a377",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55a59250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd88d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7cd86753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/.virtualenvs/datascience/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a379aac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 8, 2, 6, 6, 7, 1, 9, 8, 5])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regr.predict(x_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cbe6f5fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 16., 12.,  2.,  0.,  0.],\n",
       "       [ 0.,  0.,  4., 11., 16., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., 14., 11.,  0.,  0.],\n",
       "       [ 0.,  0.,  2.,  4., 14., 14.,  2.,  0.],\n",
       "       [ 0.,  0., 13., 16., 16., 10.,  4.,  0.],\n",
       "       [ 0.,  0.,  3., 10., 14.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., 15.,  5.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 11.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[5].reshape(8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd849249",
   "metadata": {},
   "source": [
    "Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5df6db1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f800f93eac0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_test[5].reshape(8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd3fa6a",
   "metadata": {},
   "source": [
    "### Calculate the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2cb06e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9511111111111111\n"
     ]
    }
   ],
   "source": [
    "score = logistic_regr.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da9a978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
